{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d377a50",
   "metadata": {},
   "source": [
    "For ease of running multiple experiments, the code has been extracted out of the python script and put into a jupyter notebook\n",
    "\n",
    "Below are all settins for running experiments, please uncomment the four arguments corresponding with a certain experiment.\n",
    "\n",
    "Make sure to run all cells. The last two cells will output the commandline scripts to run the ranklib script, and then run the evaluation afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82c4cd1-0e06-4083-ae6d-b7c0a9f7f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class args(object):\n",
    "    # The following lines corresponds to: Wikipedia2Vec 2019:\n",
    "    # embedding = '../src/WKN-vectors/WKN-vectors.bin'\n",
    "    # ranklib_output = 'w2vconcepts'\n",
    "    # score_output = 'w2vconcepts.txt'\n",
    "    # embedding_type = 'wikipedia2vec_old'\n",
    "\n",
    "    # The following lines corresponds to: Wikipedia2Vec 2015:\n",
    "    # embedding = '../src/wikipedia2vec_trained_20151002/wikipedia-20151002_trained_500' \n",
    "    # ranklib_output = 'w2v2015concepts'\n",
    "    # score_output = 'w2v2015concepts.txt'\n",
    "    # embedding_type = 'wikipedia2vec'\n",
    "    \n",
    "    #The following lines corresponds to: rdf2vec\n",
    "    embedding = '../src/walks_1306/model.kv'\n",
    "    ranklib_output = 'rdf2vec1306concepts'\n",
    "    score_output = 'rdf2vec1306concepts.txt'\n",
    "    embedding_type = \"rdf2vec\"\n",
    "\n",
    "    # The following lines corresponds to: rdf2vec + pagelinks\n",
    "    # embedding = '../src/walks_1708/model.kv'\n",
    "    # ranklib_output = 'rdf2vec1708concepts'\n",
    "    # score_output = 'rdf2vec1708concepts.txt'\n",
    "    # embedding_type = \"rdf2vec\"\n",
    "\n",
    "    # The following lines corresponds to: complex\n",
    "#     embedding = '../src/20220511-231012-dbpedia_small-complex_gpu/checkpoint_best.pt'\n",
    "#     ranklib_output = 'complex2vecredconcepts'\n",
    "#     score_output = 'complex2vecredconcepts.txt'\n",
    "#     embedding_type = 'complex'\n",
    "    \n",
    "\n",
    "    # The following lines corresponds to: complex + pagelinks\n",
    "    # embedding = '../src/20220818-151937-dbpedia_pagelinks-complex_gpu/checkpoint_best.pt'\n",
    "    # ranklib_output ='complex2vecpagelinksconcepts'\n",
    "    # score_output = 'complex2vecpagelinksconcepts.txt'\n",
    "    # embedding_type = 'complex'\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Use any of the following linkers, or other linkers in the /Data directory: \n",
    "\n",
    "    linker = \"../Data/geeer_ready.csv\"\n",
    "    #linker = \"../Data/geeer_annotated_radboud.csv\"\n",
    "    #linker = \"../Data/geeer_annotated_ELQ.csv\"\n",
    "    #linker = \"../Data/geeer_annotated_total.csv\"\n",
    "\n",
    "\n",
    "\n",
    "    dbpedia_input = \"../src/DBpedia-Entity/runs/v2/bm25f-ca_v2.run\"\n",
    "    def __init__(self, i_var):\n",
    "        self.i_var = i_var\n",
    "\n",
    "path_to_dbpedia = \"../src/DBpedia-Entity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5ba190-e7de-4516-a84a-923b42361c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.1\n"
     ]
    }
   ],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a973fae-5945-478e-bb39-33eca08aa6a2",
   "metadata": {},
   "source": [
    "def entity_converter(word, reverse = False, nospace = True):\n",
    "    # Input: an entity string in dbpedia format\n",
    "    # Output: string in wikipedia2vec format or readible format\n",
    "    # Getting entities in the right format\n",
    "    if args.embedding_type == 'rdf2vec':\n",
    "            word = word.replace(\"<dbpedia:\", \"http://dbpedia.org/resource/\")\n",
    "            word = word.replace(\">\", \"\")\n",
    "            return(word)\n",
    "    elif args.embedding_type == 'complex':\n",
    "        word = word.replace(\"dbpedia:\", \"http://dbpedia.org/resource/\")\n",
    "        return(word)\n",
    "    elif reverse:\n",
    "        word = word.replace(\"<dbpedia:\", \"\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        if nospace:\n",
    "            return word\n",
    "        else:\n",
    "            word = word.replace(\"_\", \" \")\n",
    "            return word\n",
    "    else:\n",
    "        word = word.replace(\"<dbpedia:\", \"ENTITY/\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80790104-960a-43b5-b91e-5fd5cdf4c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_lookup(tag, model, tagme = False):\n",
    "    # Input: entity string\n",
    "    # Output: True wikipedia2vec format\n",
    "    # Looking up the embedding of entities, returning [] when entity not in corpus\n",
    "    if tagme and args.embedding_type == 'rdf2vec':\n",
    "        tag = tag.replace('ENTITY/', 'http://dbpedia.org/resource/')\n",
    "    elif tagme and args.embedding_type == 'complex':\n",
    "        tag = tag.replace('ENTITY/', '<http://dbpedia.org/resource/')\n",
    "        tag = tag + '>'\n",
    "    elif tagme and args.embedding_type == 'wikipedia2vec':\n",
    "        tag = tag.replace('ENTITY/', '')\n",
    "        tag = tag.replace('_', ' ')\n",
    "    elif tagme and args.embedding_type == 'wikipedia2vec_old':\n",
    "        tag = tag\n",
    "    elif tag in redirect_dict:\n",
    "        tag = redirect_dict[tag]\n",
    "    else:\n",
    "        try: \n",
    "            backup = entity_converter(redirect_dict[tag])\n",
    "        except KeyError as e:\n",
    "            backup = ''\n",
    "        tag = entity_converter(tag)\n",
    "    if args.embedding_type == 'wikipedia2vec': \n",
    "        if model.get_entity(tag):\n",
    "            return model.get_entity_vector(tag)\n",
    "        elif model.get_entity(backup):\n",
    "            #print(tag, backup)\n",
    "            return model.get_entity_vector(backup)\n",
    "        else:\n",
    "            return []\n",
    "    if args.embedding_type == 'rdf2vec' or args.embedding_type == 'wikipedia2vec_old':\n",
    "        #if tag in model.vocab:\n",
    "        if tag in model.key_to_index:\n",
    "            return model[tag]\n",
    "        # elif backup in model.vocab:\n",
    "        #     #print(tag, backup)\n",
    "        #     return model[backup]\n",
    "        else:\n",
    "            return []\n",
    "    if args.embedding_type == 'complex': \n",
    "        #if tag in model.dataset.entity_ids():\n",
    "        if tag in entity_ids_dict:\n",
    "            #ent_index = model.dataset.entity_ids().index(tag)\n",
    "            ent_index = entity_ids_dict[tag]\n",
    "            model_tag = model.get_s_embedder().embed(torch.Tensor([ent_index]).long())\n",
    "            return model_tag\n",
    "        elif backup in entity_ids_dict:\n",
    "            ent_index = entity_ids_dict[backup]\n",
    "            model_tag = model.get_s_embedder().embed(torch.Tensor([ent_index]).long())\n",
    "            #print(tag, backup)\n",
    "\n",
    "            return model_tag\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5e175f-deb9-4c3c-9a8c-eccadbf15352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_converter(word, reverse = False, nospace = True):\n",
    "    # Input: an entity string in dbpedia format\n",
    "    # Output: string in wikipedia2vec format or readible format\n",
    "    # Getting entities in the right format\n",
    "    if args.embedding_type == 'rdf2vec':\n",
    "        word = word.replace(\"<dbpedia:\", \"http://dbpedia.org/resource/\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        return(word)\n",
    "    elif args.embedding_type == 'complex':\n",
    "        word = word.replace(\"dbpedia:\", \"http://dbpedia.org/resource/\")\n",
    "        return(word)\n",
    "    elif args.embedding_type == 'wikipedia2vec':\n",
    "        word = word.replace(\"<dbpedia:\", \"\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        word = word.replace(\"_\", \" \")\n",
    "        return(word)\n",
    "    elif args.embedding_type == 'wikipedia2vec_old':\n",
    "        word = word.replace(\"<dbpedia:\", \"ENTITY/\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        return word\n",
    "    elif reverse:\n",
    "        word = word.replace(\"<dbpedia:\", \"\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        if nospace:\n",
    "            return word\n",
    "        else:\n",
    "            word = word.replace(\"_\", \" \")\n",
    "            return word\n",
    "    else:\n",
    "        word = word.replace(\"<dbpedia:\", \"ENTITY/\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64034aa-d8bd-4a1f-a291-4e8884cd3f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from timeit import default_timer as timer\n",
    "\n",
    "# start = timer()\n",
    "# ent_index = model.dataset.entity_ids().index('')\n",
    "# model.get_s_embedder().embed(torch.Tensor([1]).long())\n",
    "# end = timer()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efab727-2e1d-4186-98a4-af5087e1705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.embedding_type == 'complex':\n",
    "    import torch\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "def ranking_feature(query, entity, dist = \"cosine\", conf = True):\n",
    "    # Input: a query-entity pair to score, a distance function and if we want to use confidence scores\n",
    "    # Output: query-entity based score\n",
    "\n",
    "    # getting all the linked entities to the query\n",
    "    #a_ent = pd.DataFrame(confidence.loc[confidence['query_id'] == query])\n",
    "    if query not in confidence:\n",
    "    #if len(a_ent)== 0:\n",
    "        # if no linked queries, return 0\n",
    "        return 0\n",
    "    else:\n",
    "        total = 0\n",
    "        a_ent = confidence[query]\n",
    "        for row in a_ent:\n",
    "        #for index, row in a_ent.iterrows():\n",
    "            score = row['confidence']\n",
    "            #score = row['score']\n",
    "            ent1 = entity_lookup(entity, model)\n",
    "            ent2 = entity_lookup(row['tag'], model, tagme = True)\n",
    "            #ent2 = entity_lookup(row['entity'])\n",
    "            if len(ent1) == 0 or len(ent2) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if dist == 'fjaccard':\n",
    "                    dist = 1-np.minimum(ent1,ent2).sum()/np.maximum(ent1,ent2).sum()\n",
    "                elif args.embedding_type == 'complex':\n",
    "                    dist = cos(ent1, ent2).detach().numpy()[0]\n",
    "                else:\n",
    "                    dist = 1 - spatial.distance.cosine(ent1, ent2)\n",
    "                if conf:\n",
    "                    score = row['confidence']\n",
    "                    total += score*dist\n",
    "                else:\n",
    "                    total += dist\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e607f4-cec7-456f-8efe-f4be9f3149c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_print_format(queries, filepath):\n",
    "    # input: A list of queries of which we want the results\n",
    "    # output: Ranklib ready format of results\n",
    "    f = open(filepath, \"w\")\n",
    "    for q in queries:\n",
    "        entities = new_df.loc[(new_df['query_id'] == q)]\n",
    "        for index, row in entities.iterrows():\n",
    "            printstring = str(int(row['rel'])) + ' qid:' + row['query_id'] + \" 1:\" + str(row['embedding_score']) + \" 2:\" + str(row['fsdm_score']) + \" # \" + row['tag']\n",
    "            print(printstring, file = f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8db255-4924-42d9-bdf8-b09d4758a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_print_format_dict(queries, filepath):\n",
    "    # input: A list of queries of which we want the results\n",
    "    # output: Ranklib ready format of results\n",
    "    f = open(filepath, \"w\")\n",
    "    for q in queries:\n",
    "        entities = rerank[q]\n",
    "        for ent in entities.keys():\n",
    "            printstring = str(int(entities[ent]['rel'])) + ' qid:' + q + \" 1:\" + str(entities[ent]['score']) + \" 2:\" + str(entities[ent]['fsdm_score']) + \" # \" + ent\n",
    "            print(printstring, file = f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ef99ce-ddfe-4833-910a-f6188ee9b519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading auxilary files\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading auxilary files\")\n",
    "# Loading the file to rerank\n",
    "# Note, if an error is given here when loading a different file to rerank, try changing the seperator to '\\t'\n",
    "\n",
    "qrels_path = path_to_dbpedia + '/collection/v2/qrels-v2.txt'\n",
    "qrels = {}\n",
    "with open(qrels_path) as f:\n",
    "    for line in f:\n",
    "        terms = line.split()\n",
    "        if terms[0] not in qrels:\n",
    "            qrels[terms[0]] = {}\n",
    "        qrels[terms[0]][terms[2]] = terms[3]\n",
    "\n",
    "\n",
    "\n",
    "rerank_path = args.dbpedia_input\n",
    "#rerank =  pd.read_csv(rerank_path, sep='\\s+', names = ['query_id', 'x1', 'tag', 'rang', 'fsdm_score', 'x2'])\n",
    "rerank = {}\n",
    "with open(rerank_path) as f:\n",
    "    for line in f:\n",
    "        terms = line.split()\n",
    "        if terms[0] not in rerank:\n",
    "            rerank[terms[0]] = {}\n",
    "        if terms[2] in qrels[terms[0]]:\n",
    "            rel = qrels[terms[0]][terms[2]]\n",
    "        else:\n",
    "            rel = 0\n",
    "        rerank[terms[0]][terms[2]] = {'fsdm_score' : terms[4], 'rel' : rel}\n",
    "\n",
    "\n",
    "# Loading linked entities\n",
    "#confidence = pd.read_csv(args.linker)\n",
    "\n",
    "\n",
    "confidence = {}\n",
    "with open(args.linker) as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        terms = line.strip().split(',')\n",
    "        if terms[1] not in confidence:\n",
    "            confidence[terms[1]] = []\n",
    "        try: \n",
    "            confidence[terms[1]].append({'tag' : terms[2], 'confidence' : float(terms[3])})\n",
    "        except ValueError as e:\n",
    "            conf = terms[-1]\n",
    "            tag = ','.join(terms[2:-1])\n",
    "            confidence[terms[1]].append({'tag' : tag, 'confidence' : float(conf)})\n",
    "\n",
    "\n",
    "# Loading auxilary files\n",
    "#qrels_path = path_to_dbpedia + '/collection/v2/qrels-v2.txt'\n",
    "#qrels = pd.read_csv(qrels_path, sep='\\t',names = ['query_id', '', 'tag', 'rel'])\n",
    "queries_path = path_to_dbpedia + '/collection/v2/queries-v2.txt'\n",
    "queries = pd.read_csv(queries_path, sep='\\t',names = ['query_id', 'query'])\n",
    "\n",
    "# Loading previously computed redirects\n",
    "#df = pd.read_csv('/store/usr/gerritse/results_dict/wikipedia_redirect.csv')\n",
    "df = pd.read_csv('../Data/wikipedia_redirect.csv')\n",
    "\n",
    "# Getting the data ready for further processing in RankLib\n",
    "folds_path = path_to_dbpedia + \"/collection/v2/folds/all_queries.json\"\n",
    "with open(folds_path, 'r') as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6999ee-d68d-40f6-ad80-3745d3fb8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../src/walks_1306/model.kv.vectors.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Loading the model with a Gensim keyedvector\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39membedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrdf2vec\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39membedding_type \u001b[38;5;241m==\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwikipedia2vec_old\u001b[39m\u001b[38;5;124m'\u001b[39m: \n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39membedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwikipedia2vec\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwikipedia2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wikipedia2Vec\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.11/site-packages/gensim/utils.py:487\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m compress, subname \u001b[38;5;241m=\u001b[39m SaveLoad\u001b[38;5;241m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m    486\u001b[0m obj \u001b[38;5;241m=\u001b[39m unpickle(fname)\n\u001b[0;32m--> 487\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_specials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m obj\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m, fname\u001b[38;5;241m=\u001b[39mfname)\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:263\u001b[0m, in \u001b[0;36mKeyedVectors._load_specials\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_specials\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Handle special requirements of `.load()` protocol, usually up-converting older versions.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKeyedVectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_specials\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoctags\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upconvert_old_d2vkv()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.11/site-packages/gensim/utils.py:529\u001b[0m, in \u001b[0;36mSaveLoad._load_specials\u001b[0;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[1;32m    527\u001b[0m     val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(subname(fname, attrib))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrib\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ignore_deprecation_warning():\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attrib, val)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../src/walks_1306/model.kv.vectors.npy'"
     ]
    }
   ],
   "source": [
    "print(\"Loading embeddings\")\n",
    "# Loading the model with a Gensim keyedvector\n",
    "if args.embedding_type == 'rdf2vec' or args.embedding_type ==  'wikipedia2vec_old': \n",
    "    model = gensim.models.KeyedVectors.load(args.embedding, mmap='r')\n",
    "    \n",
    "elif args.embedding_type == 'wikipedia2vec':\n",
    "    from wikipedia2vec import Wikipedia2Vec\n",
    "    model = Wikipedia2Vec.load(args.embedding)\n",
    "\n",
    "elif args.embedding_type == 'complex': \n",
    "    import torch\n",
    "    from kge import Dataset\n",
    "    from kge.model import KgeModel\n",
    "    from kge.util.io import load_checkpoint\n",
    "    checkpoint = load_checkpoint(args.embedding)\n",
    "    if args.ranklib_output == 'complex2vecpagelinksred':\n",
    "        dataset = Dataset.create(checkpoint['config'],folder = '../src/dbpedia_kge_pagelinks')\n",
    "    else:\n",
    "        dataset = Dataset.create(checkpoint['config'],folder = '../src/dbpedia_kge_small')\n",
    "\n",
    "    model = KgeModel.create_from(checkpoint, dataset)\n",
    "    entity_ids = model.dataset.entity_ids()\n",
    "    entity_ids_dict = {}\n",
    "    for i, e in enumerate(entity_ids):\n",
    "        entity_ids_dict[e] = i\n",
    "\n",
    "    import torch\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "redirect_dict = {}\n",
    "for index, tags in df.iterrows():\n",
    "    redirect_dict[tags['original']] = tags['redirect']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd226b7b-d01c-4ae9-ba02-63d52b7e25ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#redirect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ca9f25-ccaa-4ac1-9a22-ad625c7c8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a\" in model.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff988f2-eca5-4829-af52-fda6d3add474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([ 0.0267, -0.6669, -0.577 ,  0.1185,  0.3543,  0.3663,  0.6281,\n",
       "        -0.6389,  0.0808, -0.2223,  0.3297, -0.1004, -0.9479,  0.4323,\n",
       "         0.4797, -0.0581,  0.5623, -1.7071,  0.7628,  0.5647,  0.3995,\n",
       "         0.7988, -0.3355,  0.2411, -0.9855, -0.8247, -0.6165, -1.2618,\n",
       "        -0.7464,  0.084 , -0.5706, -0.1865, -0.4999, -0.4771,  0.6964,\n",
       "        -0.3774,  0.1878,  0.019 , -0.5471,  1.0492,  0.2103, -0.7212,\n",
       "         0.2763, -0.0965, -0.0764, -1.1733, -0.9302,  0.2558,  0.1496,\n",
       "         0.5607, -0.2725, -0.0023,  0.6871,  0.4769, -0.6926, -0.779 ,\n",
       "        -0.0532, -0.1834, -0.1065,  0.4034, -0.1091,  0.491 , -0.5935,\n",
       "         0.4969, -0.284 ,  1.0307, -0.0463,  0.1828, -0.4415, -0.5461,\n",
       "         0.4013, -0.2757,  0.1984, -0.914 ,  0.1912, -0.2991, -0.7957,\n",
       "         1.1819,  0.2321, -0.2361, -0.6642, -0.1363,  0.538 , -0.6315,\n",
       "        -0.4699,  0.207 , -0.0192, -0.0614,  0.4145,  0.8567, -0.4035,\n",
       "         1.2693,  0.0799, -0.2084,  0.7934, -1.7709, -0.2036, -0.3543,\n",
       "        -0.5908, -0.1911], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_lookup(entity_converter('<dbpedia:Amsterdam>'), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61459ace-0c21-43c4-ace7-ec195a1c31ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENTITY/Dutch_East_India_Company'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_converter('<dbpedia:Dutch_East_India_Company>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58080a6-daa7-42a0-9724-bbd4e0667e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([-0.0214, -0.6349, -0.6178,  0.2468,  0.4132,  0.1446,  0.1607,\n",
       "         0.6023, -0.2738, -0.2597,  0.408 , -1.471 , -1.1823,  0.0815,\n",
       "        -0.2833, -0.3059,  0.115 , -0.8741,  0.2282,  0.8581,  0.4545,\n",
       "        -0.3629, -1.0791, -0.4466,  0.2917, -1.4452, -0.0279, -2.4559,\n",
       "        -0.8016,  0.2948, -0.9418, -1.21  , -0.4692, -1.0293, -0.069 ,\n",
       "         1.1049, -0.2965,  1.3669, -0.6884,  1.013 , -0.3521, -1.0403,\n",
       "         0.6659,  1.0847, -0.2916, -1.4498, -1.1323,  0.8031, -0.5639,\n",
       "        -0.198 , -1.0912, -1.0175,  1.1082,  1.2766,  0.8299, -0.6207,\n",
       "        -0.4435,  0.4403,  0.228 ,  0.1291,  0.4034,  0.6301, -1.0996,\n",
       "        -0.335 , -0.1544,  0.9508,  0.5949, -0.6929,  0.4635, -0.0732,\n",
       "        -0.018 , -0.9697, -0.2717, -0.2482,  0.6188, -0.6333, -1.5828,\n",
       "         0.8138, -0.3467, -0.9016, -0.238 ,  0.0231,  0.0422, -0.1829,\n",
       "        -1.1991,  0.9969,  0.2114, -0.9918, -0.6421, -0.4299,  0.4223,\n",
       "         0.7993,  0.6424,  1.192 ,  0.869 , -1.6395,  0.9886, -0.7676,\n",
       "        -0.4186, -0.6774], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_lookup(entity_converter('<dbpedia:Dutch_East_India_Company>'), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11c979-e9f7-4a6a-b963-cf897c46313c",
   "metadata": {},
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "ent1 = entity_lookup(entity_converter('<dbpedia:Nijmegen>'), model)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "ent2 = entity_lookup(entity_converter('<dbpedia:Amsterdam>'), model)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "#cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "#cos(ent1, ent2).detach().numpy()[0]\n",
    "end = timer()\n",
    "print(end - start)\n",
    "#spatial.distance.cosine(ent1, ent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49271410-6a17-437c-b9aa-51af6273ee28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking entities:\n",
      "INEX_LD-2012307\n",
      "INEX_LD-2012321\n",
      "INEX_LD-2012367\n",
      "INEX_LD-20120122\n",
      "INEX_LD-20120422\n",
      "INEX_LD-20120522\n",
      "INEX_LD-2012349\n",
      "INEX_LD-2012390\n",
      "INEX_LD-2009061\n",
      "INEX_LD-2009039\n",
      "INEX_LD-2012381\n",
      "INEX_LD-2010037\n",
      "INEX_LD-2009063\n",
      "INEX_LD-2012389\n",
      "INEX_LD-2010043\n",
      "INEX_LD-2010057\n",
      "INEX_LD-2012361\n",
      "INEX_LD-2012337\n",
      "INEX_LD-2009115\n",
      "INEX_LD-2012363\n",
      "INEX_LD-20120312\n",
      "INEX_LD-2012375\n",
      "INEX_LD-2012305\n",
      "INEX_LD-20120232\n",
      "INEX_LD-2012331\n",
      "INEX_LD-20120121\n",
      "INEX_LD-2012357\n",
      "INEX_LD-20120231\n",
      "INEX_LD-20120512\n",
      "INEX_LD-20120332\n",
      "INEX_LD-2010004\n",
      "INEX_LD-20120212\n",
      "INEX_LD-2009111\n",
      "INEX_LD-2012311\n",
      "INEX_LD-2012333\n",
      "INEX_LD-2012319\n",
      "INEX_LD-2012351\n",
      "INEX_LD-20120412\n",
      "INEX_LD-2010069\n",
      "INEX_LD-20120222\n",
      "INEX_LD-2010014\n",
      "INEX_LD-2012339\n",
      "INEX_LD-2010100\n",
      "INEX_LD-2012335\n",
      "INEX_LD-2012365\n",
      "INEX_LD-2012359\n",
      "INEX_LD-2012355\n",
      "INEX_LD-20120311\n",
      "INEX_LD-2009074\n",
      "INEX_LD-20120111\n",
      "INEX_LD-2009096\n",
      "INEX_LD-20120531\n",
      "INEX_LD-20120511\n",
      "INEX_LD-2012373\n",
      "INEX_LD-20120411\n",
      "INEX_LD-2012309\n",
      "INEX_LD-2009062\n",
      "INEX_LD-20120112\n",
      "INEX_LD-2012301\n",
      "INEX_LD-2012341\n",
      "INEX_LD-20120131\n",
      "INEX_LD-2012354\n",
      "INEX_LD-2009022\n",
      "INEX_LD-2010020\n",
      "INEX_LD-2012377\n",
      "INEX_LD-2012329\n",
      "INEX_LD-2012372\n",
      "INEX_LD-20120221\n",
      "INEX_LD-2012347\n",
      "INEX_LD-2012345\n",
      "INEX_LD-20120432\n",
      "INEX_LD-20120532\n",
      "INEX_LD-2012387\n",
      "INEX_LD-20120211\n",
      "INEX_LD-20120521\n",
      "INEX_LD-20120421\n",
      "INEX_LD-2012325\n",
      "INEX_LD-20120431\n",
      "INEX_LD-2010106\n",
      "INEX_LD-2009053\n",
      "INEX_LD-20120321\n",
      "INEX_LD-2012336\n",
      "INEX_LD-2012385\n",
      "INEX_LD-2012327\n",
      "INEX_LD-2012343\n",
      "INEX_LD-2012371\n",
      "INEX_LD-2012318\n",
      "INEX_LD-2012353\n",
      "INEX_LD-2012303\n",
      "INEX_LD-20120331\n",
      "INEX_LD-2012315\n",
      "INEX_LD-20120132\n",
      "INEX_LD-20120322\n",
      "INEX_LD-2012317\n",
      "INEX_LD-2012323\n",
      "INEX_LD-2010019\n",
      "INEX_LD-2012369\n",
      "INEX_LD-2012313\n",
      "INEX_LD-2012383\n",
      "TREC_Entity-18\n",
      "SemSearch_LS-50\n",
      "INEX_XER-87\n",
      "SemSearch_LS-42\n",
      "SemSearch_LS-14\n",
      "SemSearch_LS-30\n",
      "INEX_XER-140\n",
      "TREC_Entity-17\n",
      "INEX_XER-136\n",
      "SemSearch_LS-22\n",
      "INEX_XER-139\n",
      "INEX_XER-118\n",
      "SemSearch_LS-9\n",
      "SemSearch_LS-34\n",
      "SemSearch_LS-11\n",
      "INEX_XER-60\n",
      "TREC_Entity-10\n",
      "TREC_Entity-7\n",
      "INEX_XER-126\n",
      "SemSearch_LS-8\n",
      "SemSearch_LS-26\n",
      "INEX_XER-79\n",
      "SemSearch_LS-21\n",
      "SemSearch_LS-29\n",
      "SemSearch_LS-38\n",
      "INEX_XER-119\n",
      "SemSearch_LS-25\n",
      "SemSearch_LS-40\n",
      "INEX_XER-144\n",
      "SemSearch_LS-5\n",
      "INEX_XER-91\n",
      "TREC_Entity-1\n",
      "INEX_XER-106\n",
      "INEX_XER-99\n",
      "INEX_XER-132\n",
      "SemSearch_LS-37\n",
      "INEX_XER-63\n",
      "SemSearch_LS-32\n",
      "SemSearch_LS-6\n",
      "INEX_XER-109\n",
      "INEX_XER-100\n",
      "INEX_XER-127\n",
      "INEX_XER-141\n",
      "SemSearch_LS-7\n",
      "INEX_XER-114\n",
      "INEX_XER-62\n",
      "INEX_XER-124\n",
      "INEX_XER-110\n",
      "INEX_XER-121\n",
      "SemSearch_LS-17\n",
      "INEX_XER-138\n",
      "INEX_XER-115\n",
      "INEX_XER-88\n",
      "SemSearch_LS-20\n",
      "INEX_XER-94\n",
      "INEX_XER-73\n",
      "INEX_XER-143\n",
      "SemSearch_LS-35\n",
      "INEX_XER-97\n",
      "SemSearch_LS-1\n",
      "SemSearch_LS-2\n",
      "SemSearch_LS-33\n",
      "INEX_XER-133\n",
      "INEX_XER-135\n",
      "TREC_Entity-12\n",
      "INEX_XER-98\n",
      "SemSearch_LS-36\n",
      "SemSearch_LS-44\n",
      "INEX_XER-125\n",
      "SemSearch_LS-31\n",
      "SemSearch_LS-39\n",
      "TREC_Entity-4\n",
      "INEX_XER-67\n",
      "INEX_XER-81\n",
      "TREC_Entity-14\n",
      "SemSearch_LS-13\n",
      "TREC_Entity-16\n",
      "TREC_Entity-6\n",
      "SemSearch_LS-10\n",
      "INEX_XER-117\n",
      "TREC_Entity-5\n",
      "INEX_XER-122\n",
      "SemSearch_LS-41\n",
      "INEX_XER-64\n",
      "SemSearch_LS-12\n",
      "SemSearch_LS-18\n",
      "TREC_Entity-11\n",
      "INEX_XER-134\n",
      "INEX_XER-86\n",
      "TREC_Entity-20\n",
      "INEX_XER-129\n",
      "INEX_XER-74\n",
      "INEX_XER-96\n",
      "SemSearch_LS-19\n",
      "SemSearch_LS-16\n",
      "SemSearch_LS-4\n",
      "INEX_XER-116\n",
      "INEX_XER-123\n",
      "TREC_Entity-2\n",
      "TREC_Entity-19\n",
      "SemSearch_LS-49\n",
      "INEX_XER-128\n",
      "SemSearch_LS-46\n",
      "INEX_XER-108\n",
      "INEX_XER-130\n",
      "INEX_XER-113\n",
      "INEX_XER-95\n",
      "TREC_Entity-9\n",
      "TREC_Entity-15\n",
      "INEX_XER-72\n",
      "INEX_XER-65\n",
      "INEX_XER-147\n",
      "SemSearch_LS-24\n",
      "SemSearch_LS-3\n",
      "SemSearch_LS-43\n",
      "QALD2_te-87\n",
      "QALD2_te-88\n",
      "QALD2_tr-4\n",
      "QALD2_te-59\n",
      "QALD2_tr-53\n",
      "QALD2_te-64\n",
      "QALD2_tr-28\n",
      "QALD2_tr-64\n",
      "QALD2_te-11\n",
      "QALD2_te-24\n",
      "QALD2_tr-29\n",
      "QALD2_te-91\n",
      "QALD2_te-1\n",
      "QALD2_tr-58\n",
      "QALD2_te-22\n",
      "QALD2_te-90\n",
      "QALD2_tr-21\n",
      "QALD2_te-12\n",
      "QALD2_te-63\n",
      "QALD2_tr-18\n",
      "QALD2_te-82\n",
      "QALD2_te-34\n",
      "QALD2_te-98\n",
      "QALD2_te-72\n",
      "QALD2_te-25\n",
      "QALD2_tr-77\n",
      "QALD2_tr-45\n",
      "QALD2_tr-42\n",
      "QALD2_te-8\n",
      "QALD2_tr-72\n",
      "QALD2_te-15\n",
      "QALD2_tr-59\n",
      "QALD2_te-51\n",
      "QALD2_tr-49\n",
      "QALD2_tr-50\n",
      "QALD2_tr-92\n",
      "QALD2_te-46\n",
      "QALD2_tr-65\n",
      "QALD2_tr-43\n",
      "QALD2_tr-86\n",
      "QALD2_te-81\n",
      "QALD2_te-48\n",
      "QALD2_tr-6\n",
      "QALD2_te-28\n",
      "QALD2_te-93\n",
      "QALD2_te-27\n",
      "QALD2_tr-16\n",
      "QALD2_tr-82\n",
      "QALD2_te-84\n",
      "QALD2_te-40\n",
      "QALD2_tr-83\n",
      "QALD2_te-13\n",
      "QALD2_tr-57\n",
      "QALD2_tr-52\n",
      "QALD2_te-3\n",
      "QALD2_tr-62\n",
      "QALD2_te-86\n",
      "QALD2_tr-79\n",
      "QALD2_te-5\n",
      "QALD2_tr-68\n",
      "QALD2_tr-31\n",
      "QALD2_tr-75\n",
      "QALD2_tr-32\n",
      "QALD2_tr-80\n",
      "QALD2_te-43\n",
      "QALD2_tr-24\n",
      "QALD2_te-76\n",
      "QALD2_tr-22\n",
      "QALD2_tr-38\n",
      "QALD2_te-53\n",
      "QALD2_te-58\n",
      "QALD2_te-67\n",
      "QALD2_te-2\n",
      "QALD2_te-9\n",
      "QALD2_tr-87\n",
      "QALD2_tr-26\n",
      "QALD2_te-35\n",
      "QALD2_te-77\n",
      "QALD2_tr-74\n",
      "QALD2_te-33\n",
      "QALD2_tr-55\n",
      "QALD2_tr-54\n",
      "QALD2_tr-63\n",
      "QALD2_te-66\n",
      "QALD2_te-89\n",
      "QALD2_te-42\n",
      "QALD2_te-44\n",
      "QALD2_te-55\n",
      "QALD2_tr-17\n",
      "QALD2_te-75\n",
      "QALD2_te-29\n",
      "QALD2_tr-41\n",
      "QALD2_tr-10\n",
      "QALD2_tr-84\n",
      "QALD2_te-19\n",
      "QALD2_te-95\n",
      "QALD2_tr-25\n",
      "QALD2_te-6\n",
      "QALD2_tr-91\n",
      "QALD2_te-99\n",
      "QALD2_tr-70\n",
      "QALD2_tr-36\n",
      "QALD2_te-100\n",
      "QALD2_tr-73\n",
      "QALD2_tr-3\n",
      "QALD2_te-39\n",
      "QALD2_te-97\n",
      "QALD2_te-17\n",
      "QALD2_tr-69\n",
      "QALD2_tr-47\n",
      "QALD2_tr-34\n",
      "QALD2_te-14\n",
      "QALD2_tr-40\n",
      "QALD2_tr-30\n",
      "QALD2_tr-11\n",
      "QALD2_te-80\n",
      "QALD2_tr-71\n",
      "QALD2_tr-35\n",
      "QALD2_te-92\n",
      "QALD2_tr-44\n",
      "QALD2_te-49\n",
      "QALD2_tr-23\n",
      "QALD2_tr-85\n",
      "QALD2_te-65\n",
      "QALD2_te-45\n",
      "QALD2_tr-81\n",
      "QALD2_tr-15\n",
      "QALD2_tr-9\n",
      "QALD2_tr-8\n",
      "QALD2_te-57\n",
      "QALD2_tr-13\n",
      "QALD2_te-60\n",
      "QALD2_tr-51\n",
      "QALD2_te-21\n",
      "QALD2_te-31\n",
      "QALD2_tr-61\n",
      "QALD2_tr-89\n",
      "QALD2_te-41\n",
      "QALD2_tr-78\n",
      "QALD2_tr-1\n",
      "SemSearch_ES-135\n",
      "SemSearch_ES-14\n",
      "SemSearch_ES-89\n",
      "SemSearch_ES-42\n",
      "SemSearch_ES-22\n",
      "SemSearch_ES-139\n",
      "SemSearch_ES-75\n",
      "SemSearch_ES-123\n",
      "SemSearch_ES-107\n",
      "SemSearch_ES-114\n",
      "SemSearch_ES-41\n",
      "SemSearch_ES-45\n",
      "SemSearch_ES-49\n",
      "SemSearch_ES-78\n",
      "SemSearch_ES-85\n",
      "SemSearch_ES-74\n",
      "SemSearch_ES-77\n",
      "SemSearch_ES-84\n",
      "SemSearch_ES-56\n",
      "SemSearch_ES-67\n",
      "SemSearch_ES-129\n",
      "SemSearch_ES-91\n",
      "SemSearch_ES-79\n",
      "SemSearch_ES-52\n",
      "SemSearch_ES-32\n",
      "SemSearch_ES-23\n",
      "SemSearch_ES-12\n",
      "SemSearch_ES-4\n",
      "SemSearch_ES-1\n",
      "SemSearch_ES-9\n",
      "SemSearch_ES-80\n",
      "SemSearch_ES-37\n",
      "SemSearch_ES-16\n",
      "SemSearch_ES-66\n",
      "SemSearch_ES-68\n",
      "SemSearch_ES-72\n",
      "SemSearch_ES-28\n",
      "SemSearch_ES-7\n",
      "SemSearch_ES-65\n",
      "SemSearch_ES-20\n",
      "SemSearch_ES-93\n",
      "SemSearch_ES-29\n",
      "SemSearch_ES-137\n",
      "SemSearch_ES-18\n",
      "SemSearch_ES-108\n",
      "SemSearch_ES-98\n",
      "SemSearch_ES-76\n",
      "SemSearch_ES-95\n",
      "SemSearch_ES-86\n",
      "SemSearch_ES-11\n",
      "SemSearch_ES-94\n",
      "SemSearch_ES-15\n",
      "SemSearch_ES-6\n",
      "SemSearch_ES-81\n",
      "SemSearch_ES-57\n",
      "SemSearch_ES-127\n",
      "SemSearch_ES-26\n",
      "SemSearch_ES-5\n",
      "SemSearch_ES-38\n",
      "SemSearch_ES-130\n",
      "SemSearch_ES-124\n",
      "SemSearch_ES-39\n",
      "SemSearch_ES-82\n",
      "SemSearch_ES-70\n",
      "SemSearch_ES-61\n",
      "SemSearch_ES-54\n",
      "SemSearch_ES-40\n",
      "SemSearch_ES-128\n",
      "SemSearch_ES-21\n",
      "SemSearch_ES-132\n",
      "SemSearch_ES-88\n",
      "SemSearch_ES-30\n",
      "SemSearch_ES-24\n",
      "SemSearch_ES-115\n",
      "SemSearch_ES-71\n",
      "SemSearch_ES-47\n",
      "SemSearch_ES-125\n",
      "SemSearch_ES-34\n",
      "SemSearch_ES-31\n",
      "SemSearch_ES-33\n",
      "SemSearch_ES-50\n",
      "SemSearch_ES-101\n",
      "SemSearch_ES-102\n",
      "SemSearch_ES-141\n",
      "SemSearch_ES-99\n",
      "SemSearch_ES-19\n",
      "SemSearch_ES-96\n",
      "SemSearch_ES-131\n",
      "SemSearch_ES-17\n",
      "SemSearch_ES-104\n",
      "SemSearch_ES-36\n",
      "SemSearch_ES-118\n",
      "SemSearch_ES-90\n",
      "SemSearch_ES-10\n",
      "SemSearch_ES-111\n",
      "SemSearch_ES-63\n",
      "SemSearch_ES-100\n",
      "SemSearch_ES-97\n",
      "SemSearch_ES-106\n",
      "SemSearch_ES-73\n",
      "SemSearch_ES-53\n",
      "SemSearch_ES-60\n",
      "SemSearch_ES-3\n",
      "SemSearch_ES-120\n",
      "SemSearch_ES-13\n",
      "SemSearch_ES-109\n",
      "SemSearch_ES-58\n",
      "SemSearch_ES-119\n",
      "SemSearch_ES-25\n",
      "SemSearch_ES-83\n",
      "SemSearch_ES-136\n",
      "SemSearch_ES-2\n",
      "SemSearch_ES-59\n"
     ]
    }
   ],
   "source": [
    "# Merging the qrels and rerank for scoring\n",
    "# new_df = pd.merge(qrels[['query_id','tag','rel']], rerank[['query_id','tag','fsdm_score']],  how='right', left_on=['query_id','tag'], right_on = ['query_id','tag'])\n",
    "# new_df = new_df.fillna(value = 0)\n",
    "# new_df['rel'].isna().sum()\n",
    "\n",
    "# Scoring everything (might take a while)\n",
    "test_x = []\n",
    "\n",
    "f = open(args.score_output, 'w')\n",
    "#N = len(new_df)\n",
    "#l = 50\n",
    "#m = (N/l)\n",
    "\n",
    "print(\"Ranking entities:\")\n",
    "#for index, row in new_df.iterrows():\n",
    "for query_id in rerank.keys():\n",
    "    print(query_id)\n",
    "    for tag in rerank[query_id].keys():        \n",
    "        #i = int(index/m)\n",
    "        #percentage = (100 * index) // N\n",
    "        #print('[' + '-'*i + ' '*(l-1-i)+ '] ' + str(percentage) +\"%\", flush = True, end ='\\r')\n",
    "        #print(row['query_id'],row['tag'])\n",
    "        query_based_score = ranking_feature(query_id, tag, conf = True)\n",
    "        #print(query_id, tag, query_based_score)\n",
    "        test_x.append(query_based_score)\n",
    "        #print(rerank[query_id][tag])\n",
    "        rerank[query_id][tag]['score'] = query_based_score\n",
    "        # start = timer()\n",
    "        print(\" \".join([query_id, tag, str(query_based_score)] ), file=f)\n",
    "        # #print(\" \".join([row['query_id'], row['tag'], str(query_based_score)] ))\n",
    "        # #if i > 1: \n",
    "\n",
    "\n",
    "    \n",
    "# new_df['embedding_score'] = test_x\n",
    "# print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9965e3-ab3e-4895-b045-d653c2d7af24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files for Ranklib:\n",
      "Now writing test for fold 1\n",
      "Now writing train for fold 1\n",
      "Now writing test for fold 2\n",
      "Now writing train for fold 2\n",
      "Now writing test for fold 3\n",
      "Now writing train for fold 3\n",
      "Now writing test for fold 4\n",
      "Now writing train for fold 4\n",
      "Now writing test for fold 5\n",
      "Now writing train for fold 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Saving files for Ranklib:\")\n",
    "for i in range(5):\n",
    "    query_fold = data[str(i)]\n",
    "    folder = args.ranklib_output + \"/Fold\" +str(i+1)\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    testpath = folder + \"/test.txt\"\n",
    "    print(\"Now writing test for fold \" + str(i+1))\n",
    "    to_print_format_dict(query_fold['testing'], testpath)\n",
    "\n",
    "    trainpath = folder + \"/train.txt\"\n",
    "    print(\"Now writing train for fold \" + str(i+1))\n",
    "    test_print = to_print_format_dict(query_fold['training'], trainpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "652a3066-40cb-4807-8327-a0eb66c94a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w2vELQ2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.ranklib_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9885262c-6785-4d72-9947-4f035a35ade8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash Code/train_ranklib.sh w2vELQ2\n",
      "bash Code/score_ranklib.sh w2vELQ2\n"
     ]
    }
   ],
   "source": [
    "print(f\"bash Code/train_ranklib.sh {args.ranklib_output}\")\n",
    "print(f\"bash Code/score_ranklib.sh {args.ranklib_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb7f34ae-b706-4500-8db7-d6313590d80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh eval_to_tex.sh ../w2vELQ2/embed.run\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"sh eval_to_tex.sh ../{args.ranklib_output}/embed.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba271e1e-a56c-406b-8851-471fc4d70ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1b4a8-4f69-41b4-82ae-17b14f62c10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7ceae-48c6-43c7-bb8c-deca2e56202d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
