{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1032aa-52d9-4538-bb61-57f0acbef399",
   "metadata": {},
   "source": [
    "For ease of running multiple experiments, the code has been extracted out of the python script and put into a jupyter notebook\n",
    "\n",
    "Below are all settins for running experiments, please uncomment the four arguments corresponding with a certain experiment.\n",
    "\n",
    "Make sure to run all cells. The last two cells will output the commandline scripts to run the ranklib script, and then run the evaluation afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c4cd1-0e06-4083-ae6d-b7c0a9f7f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "class args(object):\n",
    "\n",
    "    embedding = '../src/WKN-vectors/WKN-vectors.bin'\n",
    "    ranklib_output = 'w2vwebisall'\n",
    "    score_output = 'w2vwebisall.txt'\n",
    "    embedding_type = 'wikipedia2vec'\n",
    "\n",
    "    linker = '../Data/webis-qinc-22.json'\n",
    "    dbpedia_input = \"../src/DBpedia-Entity/runs/v2/bm25f-ca_v2.run\"\n",
    "    def __init__(self, i_var):\n",
    "        self.i_var = i_var\n",
    "\n",
    "path_to_dbpedia = \"../src/DBpedia-Entity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78165117-b43f-4729-b13a-af872d5ed1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.embedding):\n",
    "    print(\"Embedding file does not exist! Make sure you have unzipped the file in /src\")\n",
    "else:\n",
    "    print(\"Found Embeddings\")\n",
    "if not os.path.exists(args.dbpedia_input):\n",
    "    print(\"Dbpedia file does not exist! Make sure you have unzipped the file in /src\")\n",
    "else:\n",
    "    print(\"Found Dbpedia\")\n",
    "if not os.path.exists(args.linker):\n",
    "    print(\"Linker file does not exist!\")\n",
    "else:\n",
    "    print(\"Found Linker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3389b6-a8ed-4025-ac2e-4bfe7547f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_converter(word, reverse = False, nospace = True):\n",
    "    # Input: an entity string in dbpedia format\n",
    "    # Output: string in wikipedia2vec format or readible format\n",
    "    # Getting entities in the right format\n",
    "    if args.embedding_type == 'rdf2vec':\n",
    "            word = word.replace(\"<dbpedia:\", \"http://dbpedia.org/resource/\")\n",
    "            word = word.replace(\">\", \"\")\n",
    "            return(word)\n",
    "    elif args.embedding_type == 'complex':\n",
    "        word = word.replace(\"dbpedia:\", \"http://dbpedia.org/resource/\")\n",
    "        return(word)\n",
    "    elif reverse:\n",
    "        word = word.replace(\"<dbpedia:\", \"\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        if nospace:\n",
    "            return word\n",
    "        else:\n",
    "            word = word.replace(\"_\", \" \")\n",
    "            return word\n",
    "    else:\n",
    "        word = word.replace(\"<dbpedia:\", \"ENTITY/\")\n",
    "        word = word.replace(\">\", \"\")\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700dc06-9c3d-4e7e-8b4f-7a47d16188cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_lookup(tag, model, tagme = False):\n",
    "    # Input: entity string\n",
    "    # Output: True wikipedia2vec format\n",
    "    # Looking up the embedding of entities, returning [] when entity not in corpus\n",
    "    if tagme and args.embedding_type == 'rdf2vec':\n",
    "        tag = tag.replace('ENTITY/', 'http://dbpedia.org/resource/')\n",
    "    elif tagme and args.embedding_type == 'complex':\n",
    "        tag = tag.replace('ENTITY/', '<http://dbpedia.org/resource/')\n",
    "        tag = tag + '>'\n",
    "    elif tag in redirect_dict:\n",
    "        tag = redirect_dict[tag]\n",
    "    else:\n",
    "        tag = entity_converter(tag)\n",
    "    if args.embedding_type == 'wikipedia2vec': \n",
    "        if tag in model.key_to_index:\n",
    "            return model[tag]\n",
    "    if args.embedding_type == 'rdf2vec': \n",
    "        if tag in model.vocab:\n",
    "            return model[tag]\n",
    "        else:\n",
    "            return []\n",
    "    if args.embedding_type == 'complex': \n",
    "        #if tag in model.dataset.entity_ids():\n",
    "        if tag in entity_ids_dict:\n",
    "            #ent_index = model.dataset.entity_ids().index(tag)\n",
    "            ent_index = entity_ids_dict[tag]\n",
    "            model_tag = model.get_s_embedder().embed(torch.Tensor([ent_index]).long())\n",
    "            return model_tag\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efab727-2e1d-4186-98a4-af5087e1705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.embedding_type == 'complex':\n",
    "    import torch\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "def ranking_feature(query, entity, dist = \"cosine\", conf = True):\n",
    "    # Input: a query-entity pair to score, a distance function and if we want to use confidence scores\n",
    "    # Output: query-entity based score\n",
    "\n",
    "    # getting all the linked entities to the query\n",
    "    if query not in confidence:\n",
    "        return 0\n",
    "    \n",
    "    else:       \n",
    "        max_total = []\n",
    "        for a_ent in confidence[query]['interpretations']:\n",
    "            total = 0\n",
    "            ent_interps = [a for a in a_ent['interpretation'] if 'wikipedia' in a]\n",
    "            ent_nr = 0\n",
    "\n",
    "            for tag in ent_interps:\n",
    "            #for index, row in a_ent.iterrows():\n",
    "                #score = row['confidence']\n",
    "                score = 1\n",
    "                #score = row['score']\n",
    "                if 'wikipedia' not in tag:\n",
    "                    continue\n",
    "                tag = 'ENTITY/' + tag.split('/')[-1]    \n",
    "                ent1 = entity_lookup(entity, model)\n",
    "                ent2 = entity_lookup(tag, model, tagme = True)\n",
    "                #ent2 = entity_lookup(row['entity'])\n",
    "                if len(ent1) == 0 or len(ent2) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    ent_nr += 1\n",
    "\n",
    "                    if dist == 'fjaccard':\n",
    "                        dist = 1-np.minimum(ent1,ent2).sum()/np.maximum(ent1,ent2).sum()\n",
    "                    elif args.embedding_type == 'complex':\n",
    "                        dist = cos(ent1, ent2).detach().numpy()[0]\n",
    "                    else:\n",
    "                        dist = 1 - spatial.distance.cosine(ent1, ent2)\n",
    "                    if conf:\n",
    "                        #score = row['confidence']\n",
    "                        total += score*dist\n",
    "                    else:\n",
    "                        total += dist\n",
    "            #total = total/ent_nr if total > 0 else 0\n",
    "            #print(a_ent['interpretation'], total, ent_nr)\n",
    "            max_total.append(total)\n",
    "        #print(max_total, max(max_total))\n",
    "        #returntotal = max(max_total)\n",
    "        #returntotal = sum(max_total)/len(max_total)\n",
    "        returntotal = sum(max_total)#/len(max_total)\n",
    "        return returntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e607f4-cec7-456f-8efe-f4be9f3149c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_print_format(queries, filepath):\n",
    "    # input: A list of queries of which we want the results\n",
    "    # output: Ranklib ready format of results\n",
    "    f = open(filepath, \"w\")\n",
    "    for q in queries:\n",
    "        entities = new_df.loc[(new_df['query_id'] == q)]\n",
    "        for index, row in entities.iterrows():\n",
    "            printstring = str(int(row['rel'])) + ' qid:' + row['query_id'] + \" 1:\" + str(row['embedding_score']) + \" 2:\" + str(row['fsdm_score']) + \" # \" + row['tag']\n",
    "            print(printstring, file = f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8db255-4924-42d9-bdf8-b09d4758a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_print_format_dict(queries, filepath):\n",
    "    # input: A list of queries of which we want the results\n",
    "    # output: Ranklib ready format of results\n",
    "    f = open(filepath, \"w\")\n",
    "    for q in queries:\n",
    "        entities = rerank[q]\n",
    "        for ent in entities.keys():\n",
    "            printstring = str(int(entities[ent]['rel'])) + ' qid:' + q + \" 1:\" + str(entities[ent]['score']) + \" 2:\" + str(entities[ent]['fsdm_score']) + \" # \" + ent\n",
    "            print(printstring, file = f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef99ce-ddfe-4833-910a-f6188ee9b519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Loading auxilary files\")\n",
    "# Loading the file to rerank\n",
    "# Note, if an error is given here when loading a different file to rerank, try changing the seperator to '\\t'\n",
    "\n",
    "qrels_path = path_to_dbpedia + '/collection/v2/qrels-v2.txt'\n",
    "qrels = {}\n",
    "with open(qrels_path) as f:\n",
    "    for line in f:\n",
    "        terms = line.split()\n",
    "        if terms[0] not in qrels:\n",
    "            qrels[terms[0]] = {}\n",
    "        qrels[terms[0]][terms[2]] = terms[3]\n",
    "\n",
    "\n",
    "\n",
    "rerank_path = args.dbpedia_input\n",
    "rerank = {}\n",
    "with open(rerank_path) as f:\n",
    "    for line in f:\n",
    "        terms = line.split()\n",
    "        if terms[0] not in rerank:\n",
    "            rerank[terms[0]] = {}\n",
    "        if terms[2] in qrels[terms[0]]:\n",
    "            rel = qrels[terms[0]][terms[2]]\n",
    "        else:\n",
    "            rel = 0\n",
    "        rerank[terms[0]][terms[2]] = {'fsdm_score' : terms[4], 'rel' : rel}\n",
    "\n",
    "\n",
    "\n",
    "# Loading auxilary files\n",
    "queries_path = path_to_dbpedia + '/collection/v2/queries-v2.txt'\n",
    "queries = pd.read_csv(queries_path, sep='\\t',names = ['query_id', 'query'])\n",
    "\n",
    "# Loading previously computed redirects\n",
    "df = pd.read_csv('../Data/wikipedia_redirect.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36817a47-3345-45c3-97ea-b6253c5105e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data ready for further processing in RankLib\n",
    "folds_path = path_to_dbpedia + \"/collection/v2/folds/all_queries.json\"\n",
    "with open(folds_path, 'r') as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c5c97-e8c7-47f4-b52b-fdb8310bc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.linker) as json_file:\n",
    "    ddata = json.load(json_file)\n",
    "confidence = {}\n",
    "for q in ddata['queries']:\n",
    "    if 'dbpediav2' in q['id']:\n",
    "        new_id = q['id'][12:]\n",
    "        confidence[new_id] = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eee833-29b7-4b7f-81e2-450801725b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6999ee-d68d-40f6-ad80-3745d3fb8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading embeddings\")\n",
    "# Loading the model with a Gensim keyedvector\n",
    "if args.embedding_type == 'wikipedia2vec' or args.embedding_type == 'rdf2vec': \n",
    "    model = gensim.models.KeyedVectors.load(args.embedding, mmap='r')\n",
    "elif args.embedding_type == 'complex': \n",
    "    import torch\n",
    "    from kge import Dataset\n",
    "    from kge.model import KgeModel\n",
    "    from kge.util.io import load_checkpoint\n",
    "    checkpoint = load_checkpoint(args.embedding)\n",
    "    dataset = Dataset.create(checkpoint['config'],folder = '../Data/dbpedia_kge_small')\n",
    "    model = KgeModel.create_from(checkpoint, dataset)\n",
    "    entity_ids = model.dataset.entity_ids()\n",
    "    entity_ids_dict = {}\n",
    "    for i, e in enumerate(entity_ids):\n",
    "        entity_ids_dict[e] = i\n",
    "\n",
    "\n",
    "redirect_dict = {}\n",
    "for index, tags in df.iterrows():\n",
    "    redirect_dict[tags['original']] = tags['redirect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd226b7b-d01c-4ae9-ba02-63d52b7e25ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff988f2-eca5-4829-af52-fda6d3add474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "entity_lookup(entity_converter('<dbpedia:Amsterdam>'), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49271410-6a17-437c-b9aa-51af6273ee28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging the qrels and rerank for scoring\n",
    "\n",
    "# Scoring everything (might take a while)\n",
    "test_x = []\n",
    "\n",
    "f = open(args.score_output, 'w')\n",
    "print(\"Ranking entities:\")\n",
    "for query_id in rerank.keys():\n",
    "    print(query_id)\n",
    "    for tag in rerank[query_id].keys():        \n",
    "        query_based_score = ranking_feature(query_id, tag, conf = True)\n",
    "        if query_based_score == 0:\n",
    "            break\n",
    "        test_x.append(query_based_score)\n",
    "        rerank[query_id][tag]['score'] = query_based_score\n",
    "        print(\" \".join([query_id, tag, str(query_based_score)] ), file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9965e3-ab3e-4895-b045-d653c2d7af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Saving files for Ranklib:\")\n",
    "for i in range(5):\n",
    "    query_fold = data[str(i)]\n",
    "    folder = args.ranklib_output + \"/Fold\" +str(i+1)\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    testpath = folder + \"/test.txt\"\n",
    "    print(\"Now writing test for fold \" + str(i+1))\n",
    "    to_print_format_dict(query_fold['testing'], testpath)\n",
    "\n",
    "    trainpath = folder + \"/train.txt\"\n",
    "    print(\"Now writing train for fold \" + str(i+1))\n",
    "    test_print = to_print_format_dict(query_fold['training'], trainpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3abcd0-9040-40f2-afc7-a3d7f48f6526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
